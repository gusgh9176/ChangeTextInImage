{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image as im\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사각형\n",
    "class rectang:\n",
    "    x1=0\n",
    "    y1=0\n",
    "    x2=0\n",
    "    y2=0\n",
    "    def __init__(self, x1, y1, x2, y2):\n",
    "        self.x1=x1\n",
    "        self.y1=y1\n",
    "        self.x2=x2\n",
    "        self.y2=y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#허프 변환\n",
    "def removeVerticalLines(img, limit):\n",
    "    lines = None\n",
    "    threshold = 100\n",
    "    minLength = 60\n",
    "    lineGap = 10\n",
    "    rho = 1\n",
    "    lines = cv2.HoughLinesP(img, rho, np.pi/180, threshold, minLength, lineGap)\n",
    "    for i in range(len(lines)):\n",
    "        for x1, y1, x2, y2 in lines[i]:    \n",
    "            gapY = abs(y2-y1)\n",
    "            gapX = abs(x2-x1)\n",
    "            if(gapY>limit or gapX>limit and limit>0):\n",
    "                cv2.line(img, (x1,y1), (x2,y2), (0, 0, 0), 3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change1(img):\n",
    "    temp_img = img.copy()\n",
    "    temp_img = cv2.bilateralFilter(temp_img,9,75,75)\n",
    "    #노이즈 제거 위한 커널(erode)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    erode = cv2.erode(temp_img, kernel, iterations=1)\n",
    "    #이미지 grayscale\n",
    "    gray = cv2.cvtColor(temp_img, cv2.COLOR_BGR2GRAY)\n",
    "    #global 이진화\n",
    "    ret1, th = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "    canny = cv2.Canny(th,180,250, apertureSize = 5)\n",
    "    #직선 제거\n",
    "    removeVerticalLines(canny, 70)\n",
    "#     cv2.imshow(\"canny\",canny)\n",
    "    return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서플로우에 전달할 이미지를 저장할 배열\n",
    "image_List=[]\n",
    "\n",
    "#rectangle 배열\n",
    "rect_List = []\n",
    "\n",
    "#이미지 변수에 저장\n",
    "src = cv2.imread(\"image2.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#drawContours 가 원본이미지를 변경하기에 이미지 복사\n",
    "img1 = src.copy() #처음 Contours 그려짐\n",
    "img2 = src.copy() #Rectangle Contours 그려짐\n",
    "img3 = src.copy() #정리후 Rectangle Contours 그려짐\n",
    "\n",
    "#CannyEdge\n",
    "canny = change1(src)\n",
    "\n",
    "#Contours 찾음\n",
    "contours, hierachy = cv2.findContours(canny, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#그림에 Contours 그림\n",
    "cv2.drawContours(img1, contours, -1, (0,255,0),1)\n",
    "\n",
    "#Contours를 사각형으로 만듬\n",
    "for cnt in contours:\n",
    "    \n",
    "    #크기 작은 사격형 Contours 그리지 않음\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w)/h\n",
    "    if (w<70) or (h<50):\n",
    "        continue\n",
    "    #rectangle 좌표들 배열에 저장\n",
    "    rect_List.append(rectang(x, y, x+w, y+h))\n",
    "\n",
    "#사각형 내부의 사각형 제거. 가로,세로 좌표가 다른 사각형 내부에 포함되면 그려지지않게함\n",
    "for r1 in rect_List:\n",
    "    switch = True\n",
    "    for r2 in rect_List:\n",
    "        if ((r2.x1 < r1.x1 and r1.x1 < r2.x2) and (r2.y1 < r1.y1 and r1.y1 < r2.y2))and ((r2.x1 < r1.x1 and r1.x1 < r2.x2) and (r2.y1 < r1.y2 and r1.y2 < r2.y2))or (((r2.x1 < r1.x2 and r1.x2 < r2.x2) and (r2.y1 < r1.y1 and r1.y1 < r2.y2))and ((r2.x1 < r1.x2 and r1.x2 < r2.x2) and (r2.y1 < r1.y2 and r1.y2 < r2.y2))):\n",
    "            switch=False\n",
    "            continue\n",
    "    #해당 될시 그리는부분 스킵\n",
    "    if(switch):\n",
    "        img2 = cv2.rectangle(img2,(r1.x1, r1.y1),(r1.x2, r1.y2),(0,255,0),1)\n",
    "    \n",
    "        #배열에 텐서플로우에 전달할 이미지 저장\n",
    "        dst = src.copy()\n",
    "        dst = src[r1.y1:r1.y2, r1.x1:r1.x2]\n",
    "        dst_gray = cv2.cvtColor(dst,cv2.COLOR_BGR2GRAY)\n",
    "        dst_ret, dst_gray = cv2.threshold(dst_gray, 127,255,cv2.THRESH_BINARY)\n",
    "        dst_laplacian = cv2.Laplacian(dst_gray,cv2.CV_8U)\n",
    "        image_List.append(dst_laplacian)\n",
    "\n",
    "i=1\n",
    "for passImage in image_List:\n",
    "    name = \"image\"\n",
    "    #자른 이미지 저장\n",
    "    #path='trainImage/'+name+str(i)\n",
    "    #cv2.imwrite(path+'.jpg', passImage)\n",
    "    #cv2.imshow(name+str(i),passImage)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사각형으로 변형전 Contours 출력\n",
    "# cv2.imshow(\"img1\", img1)\n",
    "#사각형으로 변현한 Contours 출력\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/emnist-balanced-train.csv\")\n",
    "\n",
    "train, validate = train_test_split(raw_data, test_size=0.1)\n",
    "\n",
    "x_train = train.values[:,1:]\n",
    "y_train = train.values[:,0]\n",
    "\n",
    "x_validate = validate.values[:,1:]\n",
    "y_validate = validate.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_classes = 47\n",
    "epochs = 1\n",
    "\n",
    "charInd = random.randint(0,10000) # select random index in dataset for testing\n",
    "emnist = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabdefghnqrt\"\n",
    "\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_validate = x_validate.reshape(x_validate.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_validate = x_validate.reshape(x_validate.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_validate = x_validate.astype('float32')\n",
    "x_train /= 255\n",
    "x_validate /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_validate.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_validate = keras.utils.to_categorical(y_validate, num_classes)\n",
    "alphanum = np.where(y_validate[charInd]==1.)[0][0] # get index character in one-hot vector label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data augmentation features of Keras\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range = 0.075,\n",
    "    height_shift_range = 0.075,\n",
    "    rotation_range = 45,\n",
    "    shear_range = 0.075,\n",
    "    zoom_range = 0.05,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 0,\n",
    "    \n",
    ")\n",
    "\n",
    "# datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape)) # Convolutional layer - 32 filters, 5x5 kernel size\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), # Convolutional layer - 32 filters, 3x3 kernel size\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # max pooling layer - 2x2 pool window size\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5,\n",
    "                              patience = 2, min_lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "# model.load_weights('conv-model.h5')\n",
    "\n",
    "### comment back in to train ###\n",
    "model.fit_generator(datagen.flow(x_train, \n",
    "                                  y_train, \n",
    "                                  batch_size = batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (x_validate, y_validate),\n",
    "                    callbacks = [reduce_lr])\n",
    "\n",
    "score = model.evaluate(x_validate, y_validate, verbose = 0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"conv-model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"conv-model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "randChar = np.array([x_validate[charInd,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert to dataset format ###\n",
    "\n",
    "newChar = image_List[3]\n",
    "newChar = np.array(newChar)/255.\n",
    "newChar.reshape(28,28)\n",
    "nChar = np.zeros((1,28,28,1))\n",
    "for i in range(28):\n",
    "  for j in range(28):\n",
    "    nChar[0][i][j][0] = newChar.T[i][j]\n",
    "\n",
    "\n",
    "prediction2 = model.predict(nChar)\n",
    "print(prediction2)\n",
    "\n",
    "pred = secondPred = predIndex = secondPredIndex = thirdPred = thirdPredIndex = 0\n",
    "\n",
    "for i in range(47):\n",
    "  if prediction2[0][i] > pred:\n",
    "    pred = prediction2[0][i]\n",
    "    predIndex = i\n",
    "for i in range(47):\n",
    "  if prediction2[0][i] > secondPred and i != predIndex:\n",
    "    secondPred = prediction2[0][i]\n",
    "    secondPredIndex = i\n",
    "for i in range(47):\n",
    "  if prediction2[0][i] > thirdPred and i != predIndex and i != secondPredIndex:\n",
    "    thirdPred = prediction2[0][i]\n",
    "    thirdPredIndex = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newChar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-023c655fa4a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#np.reshape(nChar, (28,28))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"random character\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewChar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newChar' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Random character: \"+str(emnist[alphanum]))\n",
    "print(\"1st guess: \" + emnist[predIndex]+\", probability: \" + str(100*pred)+\"%\")\n",
    "print(\"2nd guess: \" + emnist[secondPredIndex]+\", probability: \" + str(100*secondPred)+\"%\")\n",
    "print(\"3rd guess: \" + emnist[thirdPredIndex]+\", probability: \" + str(100*thirdPred)+\"%\")\n",
    "\n",
    "#np.reshape(nChar, (28,28))\n",
    "cv2.imshow(\"random character\",np.array(newChar))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
